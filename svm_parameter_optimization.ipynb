{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Parameter Optimization Experiment\n",
    "\n",
    "This notebook implements a Support Vector Machine (SVM) parameter optimization experiment using the Breast Cancer Wisconsin dataset. We'll evaluate SVM performance across multiple samples and kernel configurations, tracking convergence and identifying the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# Display dataset information\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Target classes: {np.unique(y)}\")\n",
    "print(f\"Class names: {data.target_names}\")\n",
    "print(f\"Class distribution: {pd.Series(y).value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create output directories for saving results and figures\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('figures', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# View feature statistics\n",
    "X.describe().T.sort_values(by='mean', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x=y)\n",
    "plt.xticks([0, 1], data.target_names)\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Target Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Hyperparameter ranges\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "C_range = np.logspace(-3, 3, 10)\n",
    "gamma_range = np.logspace(-3, 3, 10)\n",
    "\n",
    "print(f\"Kernels to try: {kernels}\")\n",
    "print(f\"C values: {np.round(C_range, 5)}\")\n",
    "print(f\"Gamma values: {np.round(gamma_range, 5)}\")\n",
    "\n",
    "# Plot parameter ranges on logarithmic scale\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(np.arange(len(C_range)), C_range, 'bo-')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_title('C Parameter Range (Log Scale)')\n",
    "ax1.set_xlabel('Index')\n",
    "ax1.set_ylabel('C Value')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(np.arange(len(gamma_range)), gamma_range, 'ro-')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_title('Gamma Parameter Range (Log Scale)')\n",
    "ax2.set_xlabel('Index')\n",
    "ax2.set_ylabel('Gamma Value')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parameter Optimization Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set experiment parameters\n",
    "n_samples = 10      # Number of different train/test splits to try\n",
    "n_iterations = 100  # Number of random parameter combinations per sample\n",
    "random_seed = 42    # Base random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize tracking variables\n",
    "results = []\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "best_sample = None\n",
    "convergence_data = []\n",
    "all_sample_data = {}\n",
    "\n",
    "# Outer loop over different train/test splits\n",
    "for sample in tqdm(range(n_samples), desc=\"Samples\"):\n",
    "    np.random.seed(random_seed + sample)  # reproducibility\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=random_seed + sample\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    sample_best_acc = 0\n",
    "    sample_best_params = None\n",
    "    iteration_accuracies = []\n",
    "    sample_all_results = []\n",
    "\n",
    "    # Inner loop: random search on hyperparameters\n",
    "    for iteration in tqdm(range(n_iterations), desc=f\"Sample {sample+1} Iterations\", leave=False):\n",
    "        kernel = np.random.choice(kernels)\n",
    "        C = np.random.choice(C_range)\n",
    "\n",
    "        if kernel == 'linear':\n",
    "            svm = SVC(kernel=kernel, C=C, random_state=random_seed)\n",
    "            gamma = None\n",
    "        else:\n",
    "            gamma = np.random.choice(gamma_range)\n",
    "            svm = SVC(kernel=kernel, C=C, gamma=gamma, random_state=random_seed)\n",
    "\n",
    "        svm.fit(X_train_scaled, y_train)\n",
    "        acc = svm.score(X_test_scaled, y_test)\n",
    "        iteration_accuracies.append(acc)\n",
    "        \n",
    "        # Store all results for this sample\n",
    "        sample_all_results.append({\n",
    "            'iteration': iteration,\n",
    "            'kernel': kernel,\n",
    "            'C': C,\n",
    "            'gamma': gamma,\n",
    "            'accuracy': acc\n",
    "        })\n",
    "\n",
    "        # Update bests\n",
    "        if acc > sample_best_acc:\n",
    "            sample_best_acc = acc\n",
    "            sample_best_params = dict(kernel=kernel, C=C, gamma=gamma)\n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_params = dict(kernel=kernel, C=C, gamma=gamma, sample=sample)\n",
    "            convergence_data = iteration_accuracies.copy()\n",
    "            best_sample = sample\n",
    "\n",
    "    # Store results for this sample\n",
    "    all_sample_data[f'S{sample+1}'] = pd.DataFrame(sample_all_results)\n",
    "    \n",
    "    results.append({\n",
    "        'Sample': f'S{sample+1}',\n",
    "        'Best Accuracy': round(sample_best_acc, 3),\n",
    "        'Parameters': f\"{sample_best_params['kernel']}, \"\n",
    "                      f\"{round(sample_best_params['C'], 3)}, \"\n",
    "                      f\"{round(sample_best_params['gamma'], 3) if sample_best_params['gamma'] is not None else '—'}\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create results table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nResults Table:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save results to CSV\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_path = f'results/svm_results_{timestamp}.csv'\n",
    "results_df.to_csv(results_path, index=False)\n",
    "print(f\"Results saved to {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot convergence of the overall best run\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(convergence_data, marker='o', linestyle='-', alpha=0.7)\n",
    "plt.axhline(y=best_accuracy, color='r', linestyle='--', alpha=0.5, \n",
    "            label=f'Best Accuracy: {best_accuracy:.3f}')\n",
    "\n",
    "plt.title(f'Convergence of Best SVM (Sample {best_sample+1})')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "fig_path = f'figures/convergence_{timestamp}.png'\n",
    "plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"Convergence plot saved to {fig_path}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOverall best accuracy: {best_accuracy:.3f}\")\n",
    "print(f\"Best parameters: kernel={best_params['kernel']}, C={best_params['C']:.3f}, \" +\n",
    "      f\"gamma={best_params['gamma'] if best_params['gamma'] is not None else '—'}\")\n",
    "print(f\"Found in sample: {best_sample+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize accuracy distribution by kernel type\n",
    "# Combine all results from all samples\n",
    "all_results = pd.concat(all_sample_data.values())\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='kernel', y='accuracy', data=all_results)\n",
    "plt.title('Accuracy Distribution by Kernel Type')\n",
    "plt.xlabel('Kernel')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Save figure\n",
    "kernel_fig_path = f'figures/kernel_comparison_{timestamp}.png'\n",
    "plt.savefig(kernel_fig_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"Kernel comparison plot saved to {kernel_fig_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize the relationship between C parameter and accuracy for each kernel\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for i, kernel in enumerate(kernels):\n",
    "    kernel_data = all_results[all_results['kernel'] == kernel]\n",
    "    \n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.scatter(kernel_data['C'], kernel_data['accuracy'], alpha=0.6)\n",
    "    plt.xscale('log')\n",
    "    plt.title(f'{kernel.capitalize()} Kernel')\n",
    "    plt.xlabel('C value (log scale)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "c_param_fig_path = f'figures/c_parameter_effect_{timestamp}.png'\n",
    "plt.savefig(c_param_fig_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"C parameter effect plot saved to {c_param_fig_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Final Model with Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train a final model with the best parameters\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create model with best parameters\n",
    "if best_params['kernel'] == 'linear':\n",
    "    final_model = SVC(kernel=best_params['kernel'], C=best_params['C'], random_state=random_seed)\n",
    "else:\n",
    "    final_model = SVC(kernel=best_params['kernel'], C=best_params['C'], \n",
    "                      gamma=best_params['gamma'], random_state=random_seed)\n",
    "\n",
    "# Train and evaluate\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "train_acc = final_model.score(X_train_scaled, y_train)\n",
    "test_acc = final_model.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"Training accuracy: {train_acc:.3f}\")\n",
    "print(f\"Testing accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Make predictions\n",
    "y_pred = final_model.predict(X_test_scaled)\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=data.target_names, yticklabels=data.target_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Save confusion matrix\n",
    "cm_fig_path = f'figures/confusion_matrix_{timestamp}.png'\n",
    "plt.savefig(cm_fig_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"Confusion matrix saved to {cm_fig_path}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary of Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a summary of our findings\n",
    "print(\"SVM Parameter Optimization Summary\")\n",
    "print(\"==================================\\n\")\n",
    "print(f\"Dataset: Breast Cancer Wisconsin ({X.shape[0]} samples, {X.shape[1]} features)\")\n",
    "print(f\"Experiment: {n_samples} samples, {n_iterations} iterations per sample\\n\")\n",
    "print(\"Best Results:\")\n",
    "print(f\"- Best Accuracy: {best_accuracy:.3f}\")\n",
    "print(f\"- Best Kernel: {best_params['kernel']}\")\n",
    "print(f\"- Best C: {best_params['C']:.6f}\")\n",
    "if best_params['kernel'] != 'linear':\n",
    "    print(f\"- Best Gamma: {best_params['gamma']:.6f}\")\n",
    "print(f\"- Found in Sample: {best_sample+1}\\n\")\n",
    "print(\"Final Model Performance:\")\n",
    "print(f\"- Training Accuracy: {train_acc:.3f}\")\n",
    "print(f\"- Testing Accuracy: {test_acc:.3f}\")\n",
    "\n",
    "# Also save this summary to a file\n",
    "summary_path = f'results/summary_{timestamp}.txt'\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"SVM Parameter Optimization Summary\\n\")\n",
    "    f.write(\"==================================\\n\\n\")\n",
    "    f.write(f\"Dataset: Breast Cancer Wisconsin ({X.shape[0]} samples, {X.shape[1]} features)\\n\")\n",
    "    f.write(f\"Experiment: {n_samples} samples, {n_iterations} iterations per sample\\n\\n\")\n",
    "    f.write(\"Best Results:\\n\")\n",
    "    f.write(f\"- Best Accuracy: {best_accuracy:.3f}\\n\")\n",
    "    f.write(f\"- Best Kernel: {best_params['kernel']}\\n\")\n",
    "    f.write(f\"- Best C: {best_params['C']:.6f}\\n\")\n",
    "    if best_params['kernel'] != 'linear':\n",
    "        f.write(f\"- Best Gamma: {best_params['gamma']:.6f}\\n\")\n",
    "    f.write(f\"- Found in Sample: {best_sample+1}\\n\\n\")\n",
    "    f.write(\"Final Model Performance:\\n\")\n",
    "    f.write(f\"- Training Accuracy: {train_acc:.3f}\\n\")\n",
    "    f.write(f\"- Testing Accuracy: {test_acc:.3f}\\n\")\n",
    "\n",
    "print(f\"\\nSummary saved to {summary_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
